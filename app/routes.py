import os\nimport csv\nimport json\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom flask import Blueprint, render_template, request, jsonify, send_file, make_response\nfrom io import StringIO, BytesIO\nimport tempfile\ntry:\n    from PyPDF2 import PdfReader\nexcept ImportError:\n    PdfReader = None\n\nmain = Blueprint('main', __name__)\n\n@main.route('/')\ndef index():\n    \"\"\"Main page with folder selection interface\"\"\"\n    return render_template('index.html')\n\n@main.route('/api/scan-folder', methods=['POST'])\ndef scan_folder():\n    \"\"\"API endpoint to scan a folder and return file statistics\"\"\"\n    data = request.get_json()\n    folder_path = data.get('folder_path')\n    print(folder_path)\n    \n    if not folder_path:\n        return jsonify({'error': 'No folder path provided'}), 400\n    \n    # Expand user path (handles ~)\n    folder_path = os.path.expanduser(folder_path)\n    \n    if not os.path.exists(folder_path):\n        return jsonify({'error': f'Folder does not exist: {folder_path}'}), 400\n    \n    if not os.path.isdir(folder_path):\n        return jsonify({'error': f'Path is not a directory: {folder_path}'}), 400\n    \n    try:\n        stats = analyze_folder(folder_path)\n        return jsonify(stats)\n    except PermissionError:\n        return jsonify({'error': f'Permission denied accessing folder: {folder_path}'}), 403\n    except Exception as e:\n        return jsonify({'error': f'Error analyzing folder: {str(e)}'}), 500\n\n@main.route('/api/export-csv', methods=['POST'])\ndef export_csv():\n    \"\"\"Export analysis results as CSV\"\"\"\n    data = request.get_json()\n    \n    # Create CSV content\n    output = StringIO()\n    writer = csv.writer(output)\n    \n    # Write summary section\n    writer.writerow(['FOLDER ANALYSIS SUMMARY'])\n    writer.writerow(['Total Files', data['summary']['total_files']])\n    writer.writerow(['Total Size', data['summary']['total_size_formatted']])\n    writer.writerow(['Largest File', data['summary']['largest_file']['name']])\n    writer.writerow(['Largest File Size', data['summary']['largest_file']['size_formatted']])\n    writer.writerow([])\n    \n    # Write file types section\n    writer.writerow(['FILE TYPES BY EXTENSION'])\n    writer.writerow(['Extension', 'Count', 'Total Size', 'Average Size'])\n    \n    for ext_data in data['file_types']:\n        writer.writerow([\n            ext_data['extension'],\n            ext_data['count'],\n            ext_data['total_size_formatted'],\n            ext_data['avg_size_formatted']\n        ])\n    \n    # Prepare response\n    output.seek(0)\n    response = make_response(output.getvalue())\n    response.headers['Content-Disposition'] = 'attachment; filename=folder_analysis.csv'\n    response.headers['Content-Type'] = 'text/csv'\n    \n    return response\n\n@main.route('/api/get-files-by-extension', methods=['POST'])\ndef get_files_by_extension():\n    \"\"\"API endpoint to get detailed file list for a specific extension\"\"\"\n    data = request.get_json()\n    folder_path = data.get('folder_path')\n    extension = data.get('extension')\n    \n    if not folder_path or not extension:\n        return jsonify({'error': 'Missing folder_path or extension'}), 400\n    \n    # Expand user path (handles ~)\n    folder_path = os.path.expanduser(folder_path)\n    \n    if not os.path.exists(folder_path):\n        return jsonify({'error': f'Folder does not exist: {folder_path}'}), 400\n    \n    try:\n        files = get_files_by_ext(folder_path, extension)\n        return jsonify({\n            'extension': extension,\n            'files': files,\n            'count': len(files)\n        })\n    except Exception as e:\n        return jsonify({'error': f'Error getting files: {str(e)}'}), 500\n\ndef get_files_by_ext(folder_path, target_extension):\n    \"\"\"Get all files with a specific extension\"\"\"\n    folder_path = Path(folder_path)\n    files = []\n    \n    for file_path in folder_path.rglob('*'):\n        if file_path.is_file():\n            try:\n                extension = file_path.suffix.lower() or 'No Extension'\n                if extension == target_extension:\n                    file_size = file_path.stat().st_size\n                    file_info = {\n                        'name': file_path.name,\n                        'size': file_size,\n                        'size_formatted': format_size(file_size),\n                        'relative_path': str(file_path.relative_to(folder_path)),\n                        'full_path': str(file_path),\n                        'parent_folder': str(file_path.parent.relative_to(folder_path)) if file_path.parent != folder_path else '.'\n                    }\n                    \n                    # Add page count for PDF files\n                    if target_extension.lower() == '.pdf':\n                        page_count = get_pdf_page_count(file_path)\n                        file_info['page_count'] = page_count\n                    \n                    files.append(file_info)\n            except (OSError, IOError):\n                continue\n    \n    # Sort by size (descending)\n    files.sort(key=lambda x: x['size'], reverse=True)\n    return files\n\ndef analyze_folder(folder_path):\n    \"\"\"Analyze folder and return statistics\"\"\"\n    folder_path = Path(folder_path)\n    \n    # Initialize counters\n    total_files = 0\n    total_size = 0\n    largest_file = {'name': '', 'size': 0, 'path': ''}\n    extension_stats = defaultdict(lambda: {'count': 0, 'total_size': 0, 'files': []})\n    \n    # Walk through all files\n    for file_path in folder_path.rglob('*'):\n        if file_path.is_file():\n            try:\n                file_size = file_path.stat().st_size\n                total_files += 1\n                total_size += file_size\n                \n                # Track largest file\n                if file_size > largest_file['size']:\n                    largest_file = {\n                        'name': file_path.name,\n                        'size': file_size,\n                        'path': str(file_path)\n                    }\n                \n                # Track by extension\n                extension = file_path.suffix.lower() or 'No Extension'\n                extension_stats[extension]['count'] += 1\n                extension_stats[extension]['total_size'] += file_size\n                extension_stats[extension]['files'].append({\n                    'name': file_path.name,\n                    'size': file_size,\n                    'path': str(file_path.relative_to(folder_path))\n                })\n                \n            except (OSError, IOError):\n                # Skip files that can't be accessed\n                continue\n    \n    # Format results\n    file_types = []\n    for ext, stats in extension_stats.items():\n        avg_size = stats['total_size'] / stats['count'] if stats['count'] > 0 else 0\n        file_types.append({\n            'extension': ext,\n            'count': stats['count'],\n            'total_size': stats['total_size'],\n            'total_size_formatted': format_size(stats['total_size']),\n            'avg_size': avg_size,\n            'avg_size_formatted': format_size(avg_size),\n            'files': stats['files']\n        })\n    \n    # Sort by total size (descending)\n    file_types.sort(key=lambda x: x['total_size'], reverse=True)\n    \n    # Most common file types (by count)\n    most_common = sorted(file_types, key=lambda x: x['count'], reverse=True)[:5]\n    \n    return {\n        'summary': {\n            'total_files': total_files,\n            'total_size': total_size,\n            'total_size_formatted': format_size(total_size),\n            'largest_file': {\n                'name': largest_file['name'],\n                'size': largest_file['size'],\n                'size_formatted': format_size(largest_file['size']),\n                'path': largest_file['path']\n            },\n            'most_common_types': [{'extension': ft['extension'], 'count': ft['count']} for ft in most_common]\n        },\n        'file_types': file_types\n    }\n\ndef format_size(size_bytes):\n    \"\"\"Format file size in human readable format\"\"\"\n    if size_bytes == 0:\n        return \"0 B\"\n    \n    size_names = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]\n    i = 0\n    while size_bytes >= 1024 and i < len(size_names) - 1:\n        size_bytes /= 1024.0\n        i += 1\n    \n    return f\"{size_bytes:.1f} {size_names[i]}\"\n\ndef get_pdf_page_count(file_path):\n    \"\"\"Get the number of pages in a PDF file\"\"\"\n    if not PdfReader:\n        return None\n    \n    try:\n        with open(file_path, 'rb') as file:\n            pdf_reader = PdfReader(file)\n            return len(pdf_reader.pages)\n    except Exception:\n        # Return None if PDF is corrupted, encrypted, or can't be read\n        return None